### A Pluto.jl notebook ###
# v0.15.1

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# â•”â•â•¡ 6a822a81-a6ca-474f-a2f5-233843565de9
begin
	using Pkg
	root = ".."
	Pkg.activate(root)
	
	try
		using PlutoUI, Plots, Distributions, StatsPlots, HypertextLiteral
	catch
		Pkg.instantiate()
		using PlutoUI, Plots, Distributions, StatsPlots, HypertextLiteral
	end

	theme(:wong, legend=:outerright)
end

# â•”â•â•¡ 56aa594e-41af-4475-88a3-91cb2f5e8674
html"<button onclick=present()>Present</button>"

# â•”â•â•¡ 2f35c604-99e0-11eb-2bf3-c3cdce2b370e
md"""
# The effect of subjectivity on adjective order
### Luka van der Plas
"""

# â•”â•â•¡ ca738741-eee1-4396-8cae-599712736ab0
md"""
## Contents

* Background
* Research question
* How to investigate this
* Experiments
* Results
* Discussion
* Conclusion
"""

# â•”â•â•¡ 42110c43-0dfc-4077-a2e4-d4b6b3a69899
md"""
# Background
"""

# â•”â•â•¡ c224fc59-54b8-4b2b-a3a1-509ee3ff16fd
md"""
## Adjective order
"""

# â•”â•â•¡ 9b4fbf82-44a9-4d1e-9edd-9a09a633e48f
md"""
Do you say...
* *big plastic bag* or *plastic big bag*?
* *big heavy bag* or *heavy big bag*?

Intuitions about adjective order are difficult to describe

Semantic grouping (Dixon, 1982):

$\langle \textit{value}, \textit{dimension}, \textit{physical property}, \textit{speed}, \textit{human propensity}, \textit{age}, \textit{colour} \rangle$
"""

# â•”â•â•¡ 77af885c-f608-42f2-86f6-ebaf3f6d176a
md"""
## Adjective order: the next level âœ¨

Is there an underlying factor to adjective order?

It may be **subjectivity**
"""

# â•”â•â•¡ a396084e-0620-4ea2-9b17-9ebff8c9afb4
md"""
## Subjectivity

Subjectivity: **potential for disagreement**

Caused by:
* personal taste (*beautiful*)
* vagueness (*big*)
* ...
"""

# â•”â•â•¡ 8ddcc42c-d8d1-4d78-a2e6-7ec006d0e2e4
md"## Why subjectivity?"

# â•”â•â•¡ 89612292-abab-4ecf-b670-898e630c6b4c
md"""
Subjectivity is a problem for **reference resolution**

Compare:

$[\textit{big} \, [\textit{plastic} \; \textit{bag}]]$

vs.

$[\textit{plastic} \, [\textit{big} \; \textit{bag}]]$

More efficient to first combine the adjective that is more objective (Scontras et al.,  2019)
"""

# â•”â•â•¡ 0d7dce07-de21-4dbf-918d-7329bd7fae0f
md"## Current research"

# â•”â•â•¡ 7490a3d8-b4a8-4bc3-8f31-db877fd4b1a0
md"""
Subjectivity and order are measured separately (e.g. Scontras et al., 2017)

 $\rightarrow$ no causal link

 $\rightarrow$ treated as static
"""

# â•”â•â•¡ 934a1574-cff8-45c5-8bd1-cdc45077f1a4
md"""
# Research question

**Is adjective order preference influenced by subjectivity?**

And more specifically:

**Is this sensitive to context?**
"""

# â•”â•â•¡ f39bf794-2c04-437d-9681-b4fe3f0e49c2
md"""
# How to investigate this

An experiment where I:

1. Manipulate subjectivity

2. Measure the effect on order preference

To explain how, we need some theory...
"""

# â•”â•â•¡ 9aed9b08-1cd0-4eec-909e-f10cbe779ac0
md"""
## Vague adjectives

Vagueness: **gradient interpretation**

Scalar adjectives (*big*, *long*, *expensive*): suitable for modelling
"""

# â•”â•â•¡ e3db09c7-effc-446e-8868-955d2543805d
md"""
## How big is "big"?
"""

# â•”â•â•¡ 44d06295-5049-4d53-8c31-90155c6bbb90
@bind size_vline Slider(2:49, default = 25)

# â•”â•â•¡ f60dcca8-6006-45de-aca4-10ec912d8485
begin
	x_values = 1:50
	prior_values = let
		prior = Normal(25, 5.5)
		pdf.(prior, x_values)
	end
	
	function make_threshold_plot(slider_value)
		p = plot(
			xlabel = "size",
			ylabel = "density",
			size = (500, 250),
			legend = :right,
		)
		
		plot!(p,
			1:slider_value, 
			prior_values[1:slider_value],
			color = :black, fillcolor = 7,
			fill = 0, 
			label = "not big"
		)
		
		plot!(p,
			slider_value:50,
			prior_values[slider_value:50],
			color = :black, fillcolor = 3,
			fill = 0,
			label = "big"
		)

		plot!(p, [slider_value], 
			seriestype = :vline, 
			label = nothing,
			color = :black,
		)
	end
	
	function calculate_threshold_percentage(slider_value)
		ratio = sum(prior_values[slider_value:end]) / sum(prior_values)
		percentage = round(ratio * 100, digits=1)
	end
end ;

# â•”â•â•¡ 3e2d47af-a833-489d-a779-a91476e78fbf
make_threshold_plot(size_vline)

# â•”â•â•¡ 782d5725-0555-4279-8559-d94b8d198614
let
	percentage = calculate_threshold_percentage(size_vline)
	md"""
	**$(percentage)%** of all things are "big"
	"""
end

# â•”â•â•¡ 7a8d48e6-b607-46e1-b0bf-726d0d70de7c
md"""
## Threshold values

There is a trade-off between **informativity** and **coverage**

There is no single optimal threshold value
"""

# â•”â•â•¡ 13980aa6-75fd-4c31-a391-6e940abe22ab
function make_gradable_plot(bimodality)
	prior = MixtureModel([
			Normal(25 - (bimodality * 12), 5.5 - (bimodality * 2.5)),
			Normal(25 + (bimodality * 12), 5.5 - (bimodality * 2.5)),
			])
	
	prior_values = pdf.(prior, x_values)
	
	p = plot(
		xlabel = "size",
		ylabel = "density",
		size = (600, 280),
		legend = :none,
		colorbar = :none,
	)
	

	z_values = map(x_values) do x
		1 / (1 + exp(-0.5*(x-27)))
	end
	grad = cgrad([PlotThemes.wong_palette[7], PlotThemes.wong_palette[3]])
	
	plot!(p,
		x_values,
		prior_values,
		color = :black,
		fill = 0,
		fill_z = z_values,
		fillcolor = grad,
	)
	
	p
end ;

# â•”â•â•¡ f9a34cd2-fab0-4d65-b18e-63a1f4ddc621
make_gradable_plot(0.0)

# â•”â•â•¡ 0012e487-6e13-4b24-a805-8a815a1aa74b
md"""
## The prior distribution
"""

# â•”â•â•¡ 421b73e5-2ec2-4cd1-87f1-d347bc11c18b
@bind plot_bimodality_index Slider(0.2 :0.05: 1.0, default = 0.2)

# â•”â•â•¡ 212160ed-47fd-40e5-b42c-e4a4d449194e
make_gradable_plot(plot_bimodality_index)

# â•”â•â•¡ 4aacd22c-c0c0-42f3-be77-48780121f7bf
md"""
# Experiments
"""

# â•”â•â•¡ a2567683-1b7a-41a0-970f-8b7fccc085ea
md"""
## Design
"""

# â•”â•â•¡ fcbf9525-abed-4343-a641-039000cc9b01
md"3 experiments"

# â•”â•â•¡ 331f2e9c-e94e-47a6-8213-d5e22ada4e48
md"""
**Conditions**

* Unimodal distribution
* Bimodal distribution
"""

# â•”â•â•¡ 56c97bea-8779-4a81-b5eb-e69f020cb23f
md"""
**Target adjectives**

* *big*
* *long*
"""

# â•”â•â•¡ 72644945-b5e6-4c43-9c23-bd4a49166a43
md"## Design"

# â•”â•â•¡ a66c5e1e-e9e0-4cf1-bafa-8e72a49af8c9
md"""
**Scenarios**
"""

# â•”â•â•¡ 40078ef0-7ad8-4959-a7ad-2667efdb9e8b
md"""
## Participants
"""

# â•”â•â•¡ 5641fd17-a25e-4762-85b0-7c398be42eda
md"Recruitment through Prolific"

# â•”â•â•¡ f4804a28-f27e-44b7-84ac-186455eace95
md"## Procedure"

# â•”â•â•¡ 017acb94-2675-4225-b34f-ee87ae241dcb
md"""
Online survey

Per scenario:
"""

# â•”â•â•¡ bc65e167-8238-4b00-8999-754ee4fc5a2b
md"""
## Scenario introduction
"""

# â•”â•â•¡ fac04ee7-2280-47cd-a00b-582ca37c84ab
md"""
14 objects per scenario

One version for each condition

Objects vary in
* **size** (*big*) or **length** (*long*)
* **price** (*expensive*, *cheap*)
"""

# â•”â•â•¡ 28ace618-9f7b-4f43-91e9-57af1c4da443
md"""
## Scenario introduction
"""

# â•”â•â•¡ dbeb2823-479f-4d63-881f-5d5f6b194e2d
md"""
## Scenario introduction
"""

# â•”â•â•¡ 1e3a799c-0aec-4fe5-a15a-ee077d0be747
md"## Scenario introduction"

# â•”â•â•¡ aec667ad-d4cf-4686-a531-75defa6fe9ed
md"## Scenario introduction"

# â•”â•â•¡ b862bafe-f46c-4cb6-ade6-9dca5767ef19
md"""
## Semantic judgement task
"""

# â•”â•â•¡ 8c874d10-3d9b-4a6d-8833-41b63bf27a4e
md"## Semantic judgement task"

# â•”â•â•¡ 7c57df4a-3c99-437c-a25a-d520f5a38a1d
html"""
<style>
table.Likert {
	border: none;
}
</style>

How confident did you feel about your selection?

<table class="Likert">
<tr>
	<td>Very doubtful</td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td>Very confident</td>
</tr>
</table>
"""

# â•”â•â•¡ 31e86552-cef8-419c-8edb-7a74b2dba3f2
md"## Acceptability judgement task"

# â•”â•â•¡ 712e70a0-63b4-4a05-932b-65afb441736a
html"""
<style>
table.Likert {
	border: none;
}
</style>

<b>I saw a big expensive TV over there</b>

<table class="Likert">
<tr>
	<td>Definitely sounds bad</td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td>Definitely sounds good</td>
</tr>
</table>
"""

# â•”â•â•¡ 5459e3a8-f813-4159-a90e-5e94000ae314
html"""
<style>
table.Likert {
	border: none;
}
</style>

<b>I saw an expensive big TV over there</b>

<table class="Likert">
<tr>
	<td>Definitely sounds bad</td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td><input type="radio"></td>
	<td>Definitely sounds good</td>
</tr>
</table>
"""

# â•”â•â•¡ fc215efc-ced0-4114-9291-8ae2ba3663ba
md"## Acceptability judgement task"

# â•”â•â•¡ c6112f98-fd00-412d-b5aa-a55326a318b8
md"""
Sentences to test adjective order:

* *I saw a big expensive TV over there.*
* *I saw an expensive big TV over there.*

Target (*big*/*long*) is combined with
* 2 scalar adjectives (*expensive*, *cheap*)
* 2 absolute adjectives (*leather*, *refurbished*, *striped*...)

 $\rightarrow$ 8 sentences per scenario

In addition: 10 fillers per scenario
"""

# â•”â•â•¡ 696635e9-cb83-4900-9046-c427d6c30b9d
md"""# Results: semantic task"""

# â•”â•â•¡ 1b6490d5-a0bb-4ea1-ac2f-2571d2392ac8
md"## Confidence ratings"

# â•”â•â•¡ 84315bb3-c780-42e3-a1af-8b21ab4e31c1
md"## Potential for disagreement"

# â•”â•â•¡ ae4f30f4-cf46-4a38-af04-a06fcdddd23d
md"""
Subjectivity is described as the *potential for disagreement*

If we would match up two random participants, how likely is it that they disagree on their judgement for an object?

$p_{\textit{disagree}} = 1 - (p_{\textit{both true}} +p_{\textit{both false}})$
$= 1 - ({p_{\textit{true}}}^2 + {p_{\textit{false}}}^2)$

More mixed responses mean higher subjectivity!
"""

# â•”â•â•¡ baad54b7-b944-4289-8ca5-72852c06020b
md"## Potential for disagreement"

# â•”â•â•¡ ecdd00f4-4dae-407d-8072-ae9f3da1a4a3
md"## Semantic model"

# â•”â•â•¡ 9711a1e4-094a-4674-a6c1-d512a3e161dd
md"""
A model of interpretation

Original model: Goodman & Frank (2016)

Two adaptations:
* Mixing in group-level thinking
* Ignoring condition
"""

# â•”â•â•¡ 84fde6a3-a9af-44f0-943c-f80a9712a274
md"""
## Semantic model: original model
"""

# â•”â•â•¡ 5dd898a8-e8d1-4846-8d52-d212a436d3d6
md"## Semantic model: composite model"

# â•”â•â•¡ 45b72705-7ed3-4ace-aa62-0cd447d0fd53
md"""Issues:
* *Practical*: no parameter for between-group distinction
* *Conceptual*: thinks on level of items, not groups

Solution:

Mix this item-level model with a group-level model

For each object...
* Determine what cluster it belongs to
* Determine if that *cluster* is big/long/etc
"""

# â•”â•â•¡ efbcc42b-4238-4e31-a6ee-fb98749a3fbc
md"## Semantic model: composite model"

# â•”â•â•¡ 92392332-1321-41fd-88bd-9c6daf33daac
md"## Semantic model: condition-blind model"

# â•”â•â•¡ 98581c36-eac9-487c-9127-0604fed057ce
md"""
Do people notice the bimodal/unimodal distinction?

The condition-blind model always believes in the same normal distribution, regardless of condition
"""

# â•”â•â•¡ c5c9b6ac-df6b-4b83-adce-115cc0ef3b5e
md"## Semantic model: condition-blind model"

# â•”â•â•¡ df8aa262-f3a8-4cfe-af8e-8aa8bd877c9d
md"## Semantic model: comparison"

# â•”â•â•¡ 717e2b1a-effd-49fa-af32-414c9ec0acc5
md"""
Paramaters estimated with MCMC sampling

Evaluated on posterior probability of data

Performance: *condition-blind > composite > original*
"""

# â•”â•â•¡ 34cab4b3-7b3d-45e1-9040-503ecd6e1c16
md"## Semantic model: comparison"

# â•”â•â•¡ 97647cf0-ec8e-4e0e-b481-24683b2fd99a
md"""
Condition-blind model shows best performance, but has conceptual issues

May indicate that participants do not base judgements on stimuli
"""

# â•”â•â•¡ 5dce214d-5d0d-4134-a69d-aecd4450bb2b
md"""
# Results: acceptability judgements
"""

# â•”â•â•¡ 56ffe1c0-ef3b-4ecb-9ff3-acf91199a02d
md"## Effect of condition"

# â•”â•â•¡ 2b37275e-645e-467b-8376-14960f3e7dfa
md"## Disagreement potential and confidence"

# â•”â•â•¡ f5721070-6141-4abe-b231-484ce50ce8d8
PlutoUI.LocalResource("./figures/order_pref_by_disagreement_and_confidence.svg")

# â•”â•â•¡ c979f17f-5437-4c7c-af1c-b351bee84f84
md"## Effect of scalar vs. absolute adjectives"

# â•”â•â•¡ 2f0e278b-3cba-41ae-b4f9-f57aea48c45b
md"""## Correlation with corpus data"""

# â•”â•â•¡ 0766fd85-0bbc-40fd-bf9d-218e11dbfde4
md"""
We can compare the order preferences to frequency data

Data: Google Ngrams corpus (Michel et al., 2011)

For each pair of adjectives, calculate a *relative frequency score*

$\textit{relative frequency} = \frac{f_{\textit{target first}} - f_{\textit{target second}}}{f_{\textit{target first}} + f_{\textit{target second}}}$

"""

# â•”â•â•¡ 4fb74102-0074-41e5-a679-8562c7867aeb
md"## Correlation with corpus data"

# â•”â•â•¡ 260592ea-a83b-4e32-a4e7-3e73923b0ff8
PlutoUI.LocalResource("./figures/order_pref_by_corpus_freq.svg")

# â•”â•â•¡ 3ddb3ba9-941c-4f4e-b063-9e1663de321a
md"## Summary of findings"

# â•”â•â•¡ bfca19f2-fc18-41f6-bc0c-8d34e3bce647
md"""
Bimodal distribution resulted in...
* Lower disagreement
* Higher confidence
So it seems to affect subjectivity!

However, **the distribution had no effect on adjective order**
"""

# â•”â•â•¡ 68d94e24-e474-45d5-9ced-4469ef2500f0
md"## Summary of findings"

# â•”â•â•¡ 470a481d-9312-4936-8de2-24cba35bfced
md"""
Significant predictors of adjective order:
* Scalar vs. absolute adjectives
* Corpus frequencies

These match expectations, but they are static
"""

# â•”â•â•¡ 53adebc5-520b-4847-ba45-15061d5053b5
md"""
# Discussion
"""

# â•”â•â•¡ ebfadab6-1ad5-4fa6-bc70-fdc405e50b89
md"## Reflection"

# â•”â•â•¡ 8699f9f8-557c-4cbb-99ce-2392f0175bc3
md"""
Context or prior expectations?
* No effect of novel objects
* Good performance of condition-blind model
"""

# â•”â•â•¡ 1a91e8f1-ff36-48af-b3b2-2bfa13dfa3f9
md"Acceptability judgments: task ambiguity"

# â•”â•â•¡ ff1f6e6a-581b-4ef6-b129-c14851da87da
md"## Implications"

# â•”â•â•¡ c63ca361-d69a-4b95-9015-338ab834c80a
md"""
Why did subjectivity not affect order?

ğŸ’¡ Subjectivity is *not the true underlying factor*

ğŸ’¡ The experiment is *too fine-grained*
"""

# â•”â•â•¡ f3264078-b62c-432c-b5a6-a18b630ea847
md"""
# Conclusion
"""

# â•”â•â•¡ 9385aaed-a6cd-4c99-8dd3-6f5305c1a03c
md"""
Context affects how much interpretation varies


No effect on adjective order

Static factors can predict order preference according to expectations
"""

# â•”â•â•¡ 3ce26006-1b16-4c1a-8d38-6060b6440196
md"## Helper code"

# â•”â•â•¡ 984abf1c-e5f4-4766-a914-cabe411cf87b
stackrows(x) = permutedims(hcat(x...),(2,1))

# â•”â•â•¡ 590d567c-0aed-4c96-a309-d659e0142b68
flex(x::Union{AbstractVector,Base.Generator}; kwargs...) = flex(x...; kwargs...)

# â•”â•â•¡ ba999f79-f020-4dd5-a3bc-9fe230b6936f
begin
	Base.@kwdef struct Div
		contents
		style=Dict()
	end
	
	Div(x) = Div(contents=x)
	
	function Base.show(io::IO, m::MIME"text/html", d::Div)
		h = @htl("""
			<div style=$(d.style)>
			$(d.contents)
			</div>
			""")
		show(io, m, h)
	end
end

# â•”â•â•¡ ba95f5ac-f775-4bc8-8c32-9f7cd836a422
function stimulus_div(img_url, size, price; scale = "Size", kwargs...)
	Div(
		HTML("""<p><img src="$(img_url)" style="max-height:5em"></p>
			<p style="margin-block-end: 0px"><b>$(scale):</b> $(size) </p>
			<p style="margin-block-end: 0px"><b>Price:</b> \$ $(price) </p>"""),
		Dict((String(k) => string(v) for (k,v) in kwargs)...)
	)
end ;

# â•”â•â•¡ c48df4d0-cd39-4c30-97b4-b40bfc37cd3a
function flex(args...; kwargs...)
	Div(;
		contents=collect(args),
		style=Dict("display" => "flex", ("flex-" * String(k) => string(v) for (k,v) in kwargs)...)
		)
end

# â•”â•â•¡ 21a75a77-30af-4ce9-b208-988b0cbe8091
function stimulus_with_checkbox(img_url, size, price)
	Div(flex(
			Div(html"""<input type="checkbox">""",
				Dict("width" => "10%", "padding-top" => "5em")),
			
			stimulus_div(img_url, size, price)
			)
	)
end; 

# â•”â•â•¡ 148b9f67-6355-4cf1-a2b0-7d34b9d7407d
flex(
	Div(md"""
		High confidence overall
		
		Higher confidence in bimodal condition $\;$ ($p = .003$)
		""",
		Dict("width" => "100%")),
	
	PlutoUI.LocalResource("./figures/confidence_aggregated.svg")
)

# â•”â•â•¡ fc13ba32-064c-4df3-aeb5-8facdd8c879f
flex(
	Div(md"""
		Lower disagreement in bimodal condition...
		
		... with exception of *big* in exp 3
		""",
		Dict("width" => "100%")),
	
	PlutoUI.LocalResource("./figures/disagreement_combined.svg")
)

# â•”â•â•¡ 7f58bc9e-cd36-4ab1-8885-2884e2e4d2b9
flex(Div(md"""
		 $\lambda$: $(@bind example_Î» Slider(0:20:200, default=100))
		""",
		Dict("width" => "50%")),
	Div(md"""
	 $c$: $(@bind example_c Slider(-0.05:0.01:0.05, default = -0.01))
	""")
)

# â•”â•â•¡ 569bc894-cdac-4b19-9cfe-6da8cfb8a0a2
flex(Div(md"""
		 $\lambda$: $(@bind example_Î»_cp Slider(0:20:200, default=100))
		""",
		Dict("width" => "33%")),
	
	Div(md"""
	 	$c$: $(@bind example_c_cp Slider(-0.05:0.01:0.05, default = -0.01))
		""",
		Dict("width" => "33%")),
	
	Div(md"""
		 $\alpha$: $(@bind example_Î±_cp Slider(0.0:0.1:1.0, default = 0.5))
		""")
)

# â•”â•â•¡ 5a8005ea-b6fb-4bdf-ac95-30edadb109bc
flex(Div(md"""
		 $\lambda$: $(@bind example_Î»_cb Slider(0:20:200, default=100))
		""",
		Dict("width" => "50%")),
	Div(md"""
	 $c$: $(@bind example_c_cb Slider(-0.05:0.01:0.05, default = -0.01))
	""")
)

# â•”â•â•¡ 6bc1af68-0732-41a1-8568-94a760c2049b
flex(
	Div(md"""
		Similar ratings between conditions.
		
		No interaction between order and condition ($p = .411$)
		""",
		Dict("width" => "100%")),
	
	PlutoUI.LocalResource("./figures/order_pref_by_condition.svg")
)

# â•”â•â•¡ 1a816ccf-13c4-4787-96e3-f68919d93d33
flex(
	Div(md"""
		Stronger preference for *target first* when combined with an absolute adjective
		
		Significant interaction between order and adjective type ($p < .001$)
		""",
		Dict("width" => "100%")),
	
	PlutoUI.LocalResource("./figures/order_pref_by_secondary_type.svg")
)

# â•”â•â•¡ ba7fe41a-7a6b-4261-a21b-7d719c6c38ad
function grid(items::AbstractMatrix; fill_width::Bool=true)
	Div(
		contents=Div.(vec(permutedims(items, [2,1]))), 
		style=Dict(
			"display" => fill_width ? "grid" : "inline-grid", 
			"grid-template-columns" => "repeat($(size(items,2)), auto)",
			"column-gap" => "1em",
		),
	)
end

# â•”â•â•¡ 731dddb0-25be-459b-a995-da9383683c56
grid([
		md"" md"**Experiment 1**" md"**Experiment 2**" md"**Experiment 3**" ;
		md"*big...*" md"*TV*" md"*TV*" md"*hoppler*" ;
		md"*long...*" md"*couch*" md"*couch*" md"*trand*" ;
	])

# â•”â•â•¡ 2052703e-bd23-46e4-a564-470736633b44
grid([
		md"" md"**Experiment 1**" md"**Experiment 2**" md"**Experiment 3**" ;
		md"Participants" md"30" md"31" md"30" ;
	])

# â•”â•â•¡ 44d1958b-6dcf-43a9-98f5-fd3f039aba49
grid([
		md"" md"**Experiment 1**" md"**Experiment 2**" md"**Experiment 3**" ;
		md"Scenario introduction" md"âœ”ï¸" md"âœ”ï¸" md"âœ”ï¸" ;
		md"Semantic task" md"" md"âœ”ï¸" md"âœ”ï¸" ;
		md"Acceptability judgements" md"âœ”ï¸" md"âœ”ï¸" md"âœ”ï¸" ;
	])

# â•”â•â•¡ 0081a2a4-b130-45e7-9ff6-595d28deaeea
grid([ 
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_01.jpg",
			"22 inches",
			"990";
			margin = "0em 1em 0em 8em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_02.jpg",
			"84 inches",
			"275";
			margin = "0em 1em 0em 1em") ;
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_03.jpg",
			"70 inches",
			"885";
			margin = "1em 1em 0em 8em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_04.jpg",
			"34 inches",
			"800"; margin = "1em 8em 0em 1em") ;
	],
)

# â•”â•â•¡ d4186ee3-7306-4e85-98c1-441c1e5cf7c4
grid([ 
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/ch_01.jpg",
			"""3'7" """,
			"360";
			scale = "Length"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/ch_02.jpg",
			"""6'7" """,
			"965";
			scale = "Length") ;
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/ch_03.jpg",
			"""5'3" """,
			"290";
			scale = "Length",
			margin = "1em 0em 0em 0em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/ch_04.jpg",
			"""9'6" """,
			scale = "Length",
			"600"; margin = "1em 0em 0em 0em") ;
	],
)

# â•”â•â•¡ 48fae675-2262-45ae-a200-cbeca8343e66
grid([ 
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/bl_01.jpg",
			"18 cm",
			"9.50";
			margin = "0em 1em 0em 8em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/bl_02.jpg",
			"14 cm",
			"10.00";
			margin = "0em 1em 0em 1em") ;
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/bl_03.jpg",
			"2.5 cm",
			"15.00";
			margin = "1em 1em 0em 8em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/bl_04.jpg",
			"5 cm",
			"19.00"; margin = "1em 8em 0em 1em") ;
	],
)

# â•”â•â•¡ 98c04373-d648-41de-97c3-7dafcfdf3661
grid([ 
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/sp_01.jpg",
			"8 cm",
			"9.50";
			scale = "Length"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/sp_02.jpg",
			"33 cm",
			"8.00";
			scale = "Length") ;
		stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/sp_03.jpg",
			"13 cm",
			"8.00";
			scale = "Length",
			margin = "1em 0em 0em 0em"
			) stimulus_div("https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/novel_objects/materials/images/sp_04.jpg",
			"30 cm",
			"11.00"; 
			scale = "Length", margin = "1em 0em 0em 0em") ;
	],
)

# â•”â•â•¡ 29b295fa-740e-4f33-ace7-50abb932ba0b
grid([stimulus_with_checkbox(
			"https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_01.jpg",
			"22 inches",
			"990"
			) stimulus_with_checkbox(
			"https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_02.jpg",
			"84 inches",
			"275") ;
		stimulus_with_checkbox(
			"https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_03.jpg",
			"70 inches",
			"885"
			) stimulus_with_checkbox(
			"https://raw.githubusercontent.com/lukavdplas/adjective-order/main/experiment/acceptability_with_semantic/materials/images/tv_04.jpg",
			"34 inches",
			"800")
		])

# â•”â•â•¡ 3cb66e59-9101-4bf0-8ecb-8e9d4c794c33
function ingredients(path::String)
	# this is from the Julia source code (evalfile in base/loading.jl)
	# but with the modification that it returns the module instead of the last object
	name = Symbol(basename(path))
	m = Module(name)
	Core.eval(m,
        Expr(:toplevel,
             :(eval(x) = $(Expr(:core, :eval))($name, x)),
             :(include(x) = $(Expr(:top, :include))($name, x)),
             :(include(mapexpr::Function, x) = $(Expr(:top, :include))(mapexpr, $name, x)),
             :(include($path))))
	m
end

# â•”â•â•¡ f5e8b788-c02b-4c63-9549-a80387bb5f5f
model = ingredients(root * "/modelling/threshold_model/model_definition.jl");

# â•”â•â•¡ cf402fa6-21c8-4f4b-b24e-f07ec5435ab7
function plot_bimodal_model(Î», c)
	scale = model.example_scale_points
	prior = model.example_bimodal
	speaker = model.VagueModel(Î», c, scale, prior)
	
	p_prior = plot(scale,
		x -> pdf(prior, x),
		legend = :none,
		title = "prior probability",
		ylabel = "P(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	p_threshold = plot(scale,
		speaker.Î¸_probabilities,
		legend = :none,
		title = "threshold probability",
		ylabel = "P_Î¸(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	p_speaker = plot(scale,
		x -> model.use_adjective(x, speaker),
		legend = :none,
		title = "speaker",
		ylabel = "S(degree)", xlabel = "degree",
		lw = 2,
	)
	
	p = plot(p_speaker, p_threshold, p_prior, 
		layout = Plots.grid(3,1, heights = [0.4, 0.4, 0.2]), 
		size = (300, 600))
end;

# â•”â•â•¡ fdb01fa2-b8a7-47e7-9834-3a60fc9481c1
function plot_unimodal_model(Î», c)
	scale = model.example_scale_points
	prior = Normal(50,10)
	speaker = model.VagueModel(Î», c, scale, prior)
	
	p_prior = plot(scale,
		x -> pdf(prior, x),
		legend = :none,
		title = "prior probability",
		ylabel = "P(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 2
	)
	
	p_threshold = plot(scale,
		speaker.Î¸_probabilities,
		legend = :none,
		title = "threshold probability",
		ylabel = "P_Î¸(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 2
	)
	
	p_speaker = plot(scale,
		x -> model.use_adjective(x, speaker),
		legend = :none,
		title = "speaker",
		ylabel = "S(degree)", xlabel = "degree",
		lw = 2, color = 2
	)
	
	p = plot(p_speaker, p_threshold, p_prior, 
		layout = Plots.grid(3,1, heights = [0.4, 0.4, 0.2]), 
		size = (300, 600))
end;

# â•”â•â•¡ aeace4bb-2fed-414c-bdbb-697dc42f0938
function plot_model(Î», c)
	p_bimodal = plot_bimodal_model(Î», c)
	p_unimodal = plot_unimodal_model(Î», c)
	
	plot(p_unimodal, p_bimodal, layout = (1,2), size = (500, 320), 
		titlefontsize = 10, guidefontsize = 8, tickfontsize = 6)
end;

# â•”â•â•¡ 5a6be561-3d5e-4eb0-aff5-cbe75150e494
plot_model(example_Î», example_c)

# â•”â•â•¡ d5d257ef-f2d9-4354-999d-17445cfd740e
function plot_bimodal_model_composite(Î», c, Î±)
	scale = model.example_scale_points
	prior = model.example_bimodal
	speaker = model.CompositeModel(Î», c, Î±, scale, prior)
	
	p_prior = plot(scale,
		x -> pdf(prior, x),
		legend = :none,
		title = "prior probability",
		ylabel = "P(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	Î¸_probs = map(scale) do x
		if x > first(scale)
			prev_x = x - step(model.example_scale_points)
			model.use_adjective(x, speaker) - model.use_adjective(prev_x, speaker)
		else
			model.use_adjective(x, speaker)
		end
	end
	
	p_threshold = plot(scale,
		Î¸_probs,
		legend = :none,
		title = "threshold probability",
		ylabel = "P_Î¸(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	p_speaker = plot(scale,
		x -> model.use_adjective(x, speaker),
		legend = :none,
		title = "speaker",
		ylabel = "S(degree)", xlabel = "degree",
		lw = 2,
	)
	
	p = plot(p_speaker, p_threshold, p_prior, 
		layout = Plots.grid(3,1, heights = [0.4, 0.4, 0.2]), 
		size = (300, 600))
end;

# â•”â•â•¡ f064ff09-40c9-4d3a-9e21-c2c3361cad17
function plot_composite_model(Î», c, Î±)
	p_bimodal = plot_bimodal_model_composite(Î», c, Î±)
	p_unimodal = plot_unimodal_model(Î», c)
	
	plot(p_unimodal, p_bimodal, layout = (1,2), size = (500, 320), 
		titlefontsize = 10, guidefontsize = 8, tickfontsize = 6)
end;

# â•”â•â•¡ 0e27f658-968e-4652-96d4-8cfd3bb3c138
plot_composite_model(example_Î»_cp, example_c_cp, example_Î±_cp)

# â•”â•â•¡ b2f3d10c-66be-4ce8-b0bb-3a5e74474b64
function plot_bimodal_model_conditionblind(Î», c)
	scale = model.example_scale_points
	prior = model.example_bimodal
	prior_unim = Normal(50,10)
	speaker = model.VagueModel(Î», c, scale, prior_unim)
	
	p_prior = plot(scale,
		x -> pdf(prior, x),
		legend = :none,
		title = "prior probability",
		ylabel = "P(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	p_threshold = plot(scale,
		speaker.Î¸_probabilities,
		legend = :none,
		title = "threshold probability",
		ylabel = "P_Î¸(degree)", xlabel = "degree",
		fill = 0,
		color = :black, fillcolor = 1
	)
	
	p_speaker = plot(scale,
		x -> model.use_adjective(x, speaker),
		legend = :none,
		title = "speaker",
		ylabel = "S(degree)", xlabel = "degree",
		lw = 2,
	)
	
	p = plot(p_speaker, p_threshold, p_prior, 
		layout = Plots.grid(3,1, heights = [0.4, 0.4, 0.2]), 
		size = (300, 600))
end;

# â•”â•â•¡ 237e136c-182c-4183-85b0-e95acb7776e6
function plot_model_conditionblind(Î», c)
	p_bimodal = plot_bimodal_model_conditionblind(Î», c)
	p_unimodal = plot_unimodal_model(Î», c)
	
	plot(p_unimodal, p_bimodal, layout = (1,2), size = (500, 320), 
		titlefontsize = 10, guidefontsize = 8, tickfontsize = 6)
end;

# â•”â•â•¡ 9de156fc-bcab-462f-b563-fae5058a00ef
plot_model_conditionblind(example_Î»_cb, example_c_cb)

# â•”â•â•¡ Cell order:
# â•Ÿâ”€56aa594e-41af-4475-88a3-91cb2f5e8674
# â•Ÿâ”€2f35c604-99e0-11eb-2bf3-c3cdce2b370e
# â•Ÿâ”€ca738741-eee1-4396-8cae-599712736ab0
# â•Ÿâ”€42110c43-0dfc-4077-a2e4-d4b6b3a69899
# â•Ÿâ”€c224fc59-54b8-4b2b-a3a1-509ee3ff16fd
# â•Ÿâ”€9b4fbf82-44a9-4d1e-9edd-9a09a633e48f
# â•Ÿâ”€77af885c-f608-42f2-86f6-ebaf3f6d176a
# â•Ÿâ”€a396084e-0620-4ea2-9b17-9ebff8c9afb4
# â•Ÿâ”€8ddcc42c-d8d1-4d78-a2e6-7ec006d0e2e4
# â•Ÿâ”€89612292-abab-4ecf-b670-898e630c6b4c
# â•Ÿâ”€0d7dce07-de21-4dbf-918d-7329bd7fae0f
# â•Ÿâ”€7490a3d8-b4a8-4bc3-8f31-db877fd4b1a0
# â•Ÿâ”€934a1574-cff8-45c5-8bd1-cdc45077f1a4
# â•Ÿâ”€f39bf794-2c04-437d-9681-b4fe3f0e49c2
# â•Ÿâ”€9aed9b08-1cd0-4eec-909e-f10cbe779ac0
# â•Ÿâ”€e3db09c7-effc-446e-8868-955d2543805d
# â•Ÿâ”€44d06295-5049-4d53-8c31-90155c6bbb90
# â•Ÿâ”€3e2d47af-a833-489d-a779-a91476e78fbf
# â•Ÿâ”€782d5725-0555-4279-8559-d94b8d198614
# â•Ÿâ”€f60dcca8-6006-45de-aca4-10ec912d8485
# â•Ÿâ”€7a8d48e6-b607-46e1-b0bf-726d0d70de7c
# â•Ÿâ”€f9a34cd2-fab0-4d65-b18e-63a1f4ddc621
# â•Ÿâ”€13980aa6-75fd-4c31-a391-6e940abe22ab
# â•Ÿâ”€0012e487-6e13-4b24-a805-8a815a1aa74b
# â•Ÿâ”€421b73e5-2ec2-4cd1-87f1-d347bc11c18b
# â•Ÿâ”€212160ed-47fd-40e5-b42c-e4a4d449194e
# â•Ÿâ”€4aacd22c-c0c0-42f3-be77-48780121f7bf
# â•Ÿâ”€a2567683-1b7a-41a0-970f-8b7fccc085ea
# â•Ÿâ”€fcbf9525-abed-4343-a641-039000cc9b01
# â•Ÿâ”€331f2e9c-e94e-47a6-8213-d5e22ada4e48
# â•Ÿâ”€56c97bea-8779-4a81-b5eb-e69f020cb23f
# â•Ÿâ”€72644945-b5e6-4c43-9c23-bd4a49166a43
# â•Ÿâ”€a66c5e1e-e9e0-4cf1-bafa-8e72a49af8c9
# â•Ÿâ”€731dddb0-25be-459b-a995-da9383683c56
# â•Ÿâ”€40078ef0-7ad8-4959-a7ad-2667efdb9e8b
# â•Ÿâ”€5641fd17-a25e-4762-85b0-7c398be42eda
# â•Ÿâ”€2052703e-bd23-46e4-a564-470736633b44
# â•Ÿâ”€f4804a28-f27e-44b7-84ac-186455eace95
# â•Ÿâ”€017acb94-2675-4225-b34f-ee87ae241dcb
# â•Ÿâ”€44d1958b-6dcf-43a9-98f5-fd3f039aba49
# â•Ÿâ”€bc65e167-8238-4b00-8999-754ee4fc5a2b
# â•Ÿâ”€fac04ee7-2280-47cd-a00b-582ca37c84ab
# â•Ÿâ”€28ace618-9f7b-4f43-91e9-57af1c4da443
# â•Ÿâ”€0081a2a4-b130-45e7-9ff6-595d28deaeea
# â•Ÿâ”€ba95f5ac-f775-4bc8-8c32-9f7cd836a422
# â•Ÿâ”€dbeb2823-479f-4d63-881f-5d5f6b194e2d
# â•Ÿâ”€d4186ee3-7306-4e85-98c1-441c1e5cf7c4
# â•Ÿâ”€1e3a799c-0aec-4fe5-a15a-ee077d0be747
# â•Ÿâ”€48fae675-2262-45ae-a200-cbeca8343e66
# â•Ÿâ”€aec667ad-d4cf-4686-a531-75defa6fe9ed
# â•Ÿâ”€98c04373-d648-41de-97c3-7dafcfdf3661
# â•Ÿâ”€b862bafe-f46c-4cb6-ade6-9dca5767ef19
# â•Ÿâ”€29b295fa-740e-4f33-ace7-50abb932ba0b
# â•Ÿâ”€21a75a77-30af-4ce9-b208-988b0cbe8091
# â•Ÿâ”€8c874d10-3d9b-4a6d-8833-41b63bf27a4e
# â•Ÿâ”€7c57df4a-3c99-437c-a25a-d520f5a38a1d
# â•Ÿâ”€31e86552-cef8-419c-8edb-7a74b2dba3f2
# â•Ÿâ”€712e70a0-63b4-4a05-932b-65afb441736a
# â•Ÿâ”€5459e3a8-f813-4159-a90e-5e94000ae314
# â•Ÿâ”€fc215efc-ced0-4114-9291-8ae2ba3663ba
# â•Ÿâ”€c6112f98-fd00-412d-b5aa-a55326a318b8
# â•Ÿâ”€696635e9-cb83-4900-9046-c427d6c30b9d
# â•Ÿâ”€1b6490d5-a0bb-4ea1-ac2f-2571d2392ac8
# â•Ÿâ”€148b9f67-6355-4cf1-a2b0-7d34b9d7407d
# â•Ÿâ”€84315bb3-c780-42e3-a1af-8b21ab4e31c1
# â•Ÿâ”€ae4f30f4-cf46-4a38-af04-a06fcdddd23d
# â•Ÿâ”€baad54b7-b944-4289-8ca5-72852c06020b
# â•Ÿâ”€fc13ba32-064c-4df3-aeb5-8facdd8c879f
# â•Ÿâ”€ecdd00f4-4dae-407d-8072-ae9f3da1a4a3
# â•Ÿâ”€9711a1e4-094a-4674-a6c1-d512a3e161dd
# â•Ÿâ”€84fde6a3-a9af-44f0-943c-f80a9712a274
# â•Ÿâ”€7f58bc9e-cd36-4ab1-8885-2884e2e4d2b9
# â•Ÿâ”€5a6be561-3d5e-4eb0-aff5-cbe75150e494
# â•Ÿâ”€f5e8b788-c02b-4c63-9549-a80387bb5f5f
# â•Ÿâ”€cf402fa6-21c8-4f4b-b24e-f07ec5435ab7
# â•Ÿâ”€fdb01fa2-b8a7-47e7-9834-3a60fc9481c1
# â•Ÿâ”€aeace4bb-2fed-414c-bdbb-697dc42f0938
# â•Ÿâ”€5dd898a8-e8d1-4846-8d52-d212a436d3d6
# â•Ÿâ”€45b72705-7ed3-4ace-aa62-0cd447d0fd53
# â•Ÿâ”€efbcc42b-4238-4e31-a6ee-fb98749a3fbc
# â•Ÿâ”€569bc894-cdac-4b19-9cfe-6da8cfb8a0a2
# â•Ÿâ”€0e27f658-968e-4652-96d4-8cfd3bb3c138
# â•Ÿâ”€d5d257ef-f2d9-4354-999d-17445cfd740e
# â•Ÿâ”€f064ff09-40c9-4d3a-9e21-c2c3361cad17
# â•Ÿâ”€92392332-1321-41fd-88bd-9c6daf33daac
# â•Ÿâ”€98581c36-eac9-487c-9127-0604fed057ce
# â•Ÿâ”€c5c9b6ac-df6b-4b83-adce-115cc0ef3b5e
# â•Ÿâ”€5a8005ea-b6fb-4bdf-ac95-30edadb109bc
# â•Ÿâ”€9de156fc-bcab-462f-b563-fae5058a00ef
# â•Ÿâ”€b2f3d10c-66be-4ce8-b0bb-3a5e74474b64
# â•Ÿâ”€237e136c-182c-4183-85b0-e95acb7776e6
# â•Ÿâ”€df8aa262-f3a8-4cfe-af8e-8aa8bd877c9d
# â•Ÿâ”€717e2b1a-effd-49fa-af32-414c9ec0acc5
# â•Ÿâ”€34cab4b3-7b3d-45e1-9040-503ecd6e1c16
# â•Ÿâ”€97647cf0-ec8e-4e0e-b481-24683b2fd99a
# â•Ÿâ”€5dce214d-5d0d-4134-a69d-aecd4450bb2b
# â•Ÿâ”€56ffe1c0-ef3b-4ecb-9ff3-acf91199a02d
# â•Ÿâ”€6bc1af68-0732-41a1-8568-94a760c2049b
# â•Ÿâ”€2b37275e-645e-467b-8376-14960f3e7dfa
# â•Ÿâ”€f5721070-6141-4abe-b231-484ce50ce8d8
# â•Ÿâ”€c979f17f-5437-4c7c-af1c-b351bee84f84
# â•Ÿâ”€1a816ccf-13c4-4787-96e3-f68919d93d33
# â•Ÿâ”€2f0e278b-3cba-41ae-b4f9-f57aea48c45b
# â•Ÿâ”€0766fd85-0bbc-40fd-bf9d-218e11dbfde4
# â•Ÿâ”€4fb74102-0074-41e5-a679-8562c7867aeb
# â•Ÿâ”€260592ea-a83b-4e32-a4e7-3e73923b0ff8
# â•Ÿâ”€3ddb3ba9-941c-4f4e-b063-9e1663de321a
# â•Ÿâ”€bfca19f2-fc18-41f6-bc0c-8d34e3bce647
# â•Ÿâ”€68d94e24-e474-45d5-9ced-4469ef2500f0
# â•Ÿâ”€470a481d-9312-4936-8de2-24cba35bfced
# â•Ÿâ”€53adebc5-520b-4847-ba45-15061d5053b5
# â•Ÿâ”€ebfadab6-1ad5-4fa6-bc70-fdc405e50b89
# â•Ÿâ”€8699f9f8-557c-4cbb-99ce-2392f0175bc3
# â•Ÿâ”€1a91e8f1-ff36-48af-b3b2-2bfa13dfa3f9
# â•Ÿâ”€ff1f6e6a-581b-4ef6-b129-c14851da87da
# â•Ÿâ”€c63ca361-d69a-4b95-9015-338ab834c80a
# â•Ÿâ”€f3264078-b62c-432c-b5a6-a18b630ea847
# â•Ÿâ”€9385aaed-a6cd-4c99-8dd3-6f5305c1a03c
# â•Ÿâ”€3ce26006-1b16-4c1a-8d38-6060b6440196
# â• â•6a822a81-a6ca-474f-a2f5-233843565de9
# â• â•984abf1c-e5f4-4766-a914-cabe411cf87b
# â• â•c48df4d0-cd39-4c30-97b4-b40bfc37cd3a
# â• â•590d567c-0aed-4c96-a309-d659e0142b68
# â• â•ba999f79-f020-4dd5-a3bc-9fe230b6936f
# â• â•ba7fe41a-7a6b-4261-a21b-7d719c6c38ad
# â• â•3cb66e59-9101-4bf0-8ecb-8e9d4c794c33
